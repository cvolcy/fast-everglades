{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"!git clone https://github.com/qqwweee/keras-yolo3.git","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!ls keras-yolo3 -l","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Download annotation data and extract it."},{"metadata":{"trusted":true},"cell_type":"code","source":"!wget -O annotations.zip \"https://drive.google.com/uc?export=download&id=1vhoSkyFgW20C0vUD8wBMqmLVc8UknpFM\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!unzip annotations.zip","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-output":false,"trusted":true},"cell_type":"code","source":"!mv annotations/ keras-yolo3/model_data/annotations","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%writefile keras-yolo3/train.py\n# %load keras-yolo3/train.py\n\"\"\"\nRetrain the YOLO model for your own dataset.\n\"\"\"\n\nimport numpy as np\nimport keras.backend as K\nfrom keras.layers import Input, Lambda\nfrom keras.models import Model\nfrom keras.optimizers import Adam\nfrom keras.callbacks import TensorBoard, ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\n\nfrom yolo3.model import preprocess_true_boxes, yolo_body, tiny_yolo_body, yolo_loss\nfrom yolo3.utils import get_random_data\n\n\ndef _main():\n    annotation_path = 'train.txt'\n    log_dir = 'logs/000/'\n    classes_path = 'model_data/voc_classes.txt'\n    anchors_path = 'model_data/yolo_anchors.txt'\n    class_names = get_classes(classes_path)\n    num_classes = len(class_names)\n    anchors = get_anchors(anchors_path)\n\n    input_shape = (416,416) # multiple of 32, hw\n\n    is_tiny_version = len(anchors)==6 # default setting\n    if is_tiny_version:\n        model = create_tiny_model(input_shape, anchors, num_classes,\n            freeze_body=2, weights_path='model_data/tiny_yolo_weights.h5')\n    else:\n        model = create_model(input_shape, anchors, num_classes,\n            freeze_body=2, weights_path='model_data/yolo_weights.h5') # make sure you know what you freeze\n\n    logging = TensorBoard(log_dir=log_dir)\n    checkpoint = ModelCheckpoint(log_dir + 'ep{epoch:03d}-loss{loss:.3f}-val_loss{val_loss:.3f}.h5',\n        monitor='val_loss', save_weights_only=True, save_best_only=True, period=3)\n    reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=3, verbose=1)\n    early_stopping = EarlyStopping(monitor='val_loss', min_delta=0, patience=10, verbose=1)\n\n    val_split = 0.1\n    with open(annotation_path) as f:\n        lines = f.readlines()\n    np.random.seed(10101)\n    np.random.shuffle(lines)\n    np.random.seed(None)\n    num_val = int(len(lines)*val_split)\n    num_train = len(lines) - num_val\n\n    # Train with frozen layers first, to get a stable loss.\n    # Adjust num epochs to your dataset. This step is enough to obtain a not bad model.\n    if True:\n        model.compile(optimizer=Adam(lr=1e-3), loss={\n            # use custom yolo_loss Lambda layer.\n            'yolo_loss': lambda y_true, y_pred: y_pred})\n\n        batch_size = 32\n        print('Train on {} samples, val on {} samples, with batch size {}.'.format(num_train, num_val, batch_size))\n        model.fit_generator(data_generator_wrapper(lines[:num_train], batch_size, input_shape, anchors, num_classes),\n                steps_per_epoch=max(1, num_train//batch_size),\n                validation_data=data_generator_wrapper(lines[num_train:], batch_size, input_shape, anchors, num_classes),\n                validation_steps=max(1, num_val//batch_size),\n                epochs=50,\n                initial_epoch=0,\n                callbacks=[logging, checkpoint])\n        model.save_weights(log_dir + 'trained_weights_stage_1.h5')\n\n    # Unfreeze and continue training, to fine-tune.\n    # Train longer if the result is not good.\n    if True:\n        for i in range(len(model.layers)):\n            model.layers[i].trainable = True\n        model.compile(optimizer=Adam(lr=1e-4), loss={'yolo_loss': lambda y_true, y_pred: y_pred}) # recompile to apply the change\n        print('Unfreeze all of the layers.')\n\n        batch_size = 8 # note that more GPU memory is required after unfreezing the body\n        print('Train on {} samples, val on {} samples, with batch size {}.'.format(num_train, num_val, batch_size))\n        model.fit_generator(data_generator_wrapper(lines[:num_train], batch_size, input_shape, anchors, num_classes),\n            steps_per_epoch=max(1, num_train//batch_size),\n            validation_data=data_generator_wrapper(lines[num_train:], batch_size, input_shape, anchors, num_classes),\n            validation_steps=max(1, num_val//batch_size),\n            epochs=100,\n            initial_epoch=50,\n            callbacks=[logging, checkpoint, reduce_lr, early_stopping])\n        model.save_weights(log_dir + 'trained_weights_final.h5')\n\n    # Further training if needed.\n\n\ndef get_classes(classes_path):\n    '''loads the classes'''\n    with open(classes_path) as f:\n        class_names = f.readlines()\n    class_names = [c.strip() for c in class_names]\n    return class_names\n\ndef get_anchors(anchors_path):\n    '''loads the anchors from a file'''\n    with open(anchors_path) as f:\n        anchors = f.readline()\n    anchors = [float(x) for x in anchors.split(',')]\n    return np.array(anchors).reshape(-1, 2)\n\n\ndef create_model(input_shape, anchors, num_classes, load_pretrained=True, freeze_body=2,\n            weights_path='model_data/yolo_weights.h5'):\n    '''create the training model'''\n    K.clear_session() # get a new session\n    image_input = Input(shape=(None, None, 3))\n    h, w = input_shape\n    num_anchors = len(anchors)\n\n    y_true = [Input(shape=(h//{0:32, 1:16, 2:8}[l], w//{0:32, 1:16, 2:8}[l], \\\n        num_anchors//3, num_classes+5)) for l in range(3)]\n\n    model_body = yolo_body(image_input, num_anchors//3, num_classes)\n    print('Create YOLOv3 model with {} anchors and {} classes.'.format(num_anchors, num_classes))\n\n    if load_pretrained:\n        model_body.load_weights(weights_path, by_name=True, skip_mismatch=True)\n        print('Load weights {}.'.format(weights_path))\n        if freeze_body in [1, 2]:\n            # Freeze darknet53 body or freeze all but 3 output layers.\n            num = (185, len(model_body.layers)-3)[freeze_body-1]\n            for i in range(num): model_body.layers[i].trainable = False\n            print('Freeze the first {} layers of total {} layers.'.format(num, len(model_body.layers)))\n\n    model_loss = Lambda(yolo_loss, output_shape=(1,), name='yolo_loss',\n        arguments={'anchors': anchors, 'num_classes': num_classes, 'ignore_thresh': 0.5})(\n        [*model_body.output, *y_true])\n    model = Model([model_body.input, *y_true], model_loss)\n\n    return model\n\ndef create_tiny_model(input_shape, anchors, num_classes, load_pretrained=True, freeze_body=2,\n            weights_path='model_data/tiny_yolo_weights.h5'):\n    '''create the training model, for Tiny YOLOv3'''\n    K.clear_session() # get a new session\n    image_input = Input(shape=(None, None, 3))\n    h, w = input_shape\n    num_anchors = len(anchors)\n\n    y_true = [Input(shape=(h//{0:32, 1:16}[l], w//{0:32, 1:16}[l], \\\n        num_anchors//2, num_classes+5)) for l in range(2)]\n\n    model_body = tiny_yolo_body(image_input, num_anchors//2, num_classes)\n    print('Create Tiny YOLOv3 model with {} anchors and {} classes.'.format(num_anchors, num_classes))\n\n    if load_pretrained:\n        model_body.load_weights(weights_path, by_name=True, skip_mismatch=True)\n        print('Load weights {}.'.format(weights_path))\n        if freeze_body in [1, 2]:\n            # Freeze the darknet body or freeze all but 2 output layers.\n            num = (20, len(model_body.layers)-2)[freeze_body-1]\n            for i in range(num): model_body.layers[i].trainable = False\n            print('Freeze the first {} layers of total {} layers.'.format(num, len(model_body.layers)))\n\n    model_loss = Lambda(yolo_loss, output_shape=(1,), name='yolo_loss',\n        arguments={'anchors': anchors, 'num_classes': num_classes, 'ignore_thresh': 0.7})(\n        [*model_body.output, *y_true])\n    model = Model([model_body.input, *y_true], model_loss)\n\n    return model\n\ndef data_generator(annotation_lines, batch_size, input_shape, anchors, num_classes):\n    '''data generator for fit_generator'''\n    n = len(annotation_lines)\n    i = 0\n    while True:\n        image_data = []\n        box_data = []\n        for b in range(batch_size):\n            if i==0:\n                np.random.shuffle(annotation_lines)\n            image, box = get_random_data(annotation_lines[i], input_shape, random=True)\n            image_data.append(image)\n            box_data.append(box)\n            i = (i+1) % n\n        image_data = np.array(image_data)\n        box_data = np.array(box_data)\n        y_true = preprocess_true_boxes(box_data, input_shape, anchors, num_classes)\n        yield [image_data, *y_true], np.zeros(batch_size)\n\ndef data_generator_wrapper(annotation_lines, batch_size, input_shape, anchors, num_classes):\n    n = len(annotation_lines)\n    if n==0 or batch_size<=0: return None\n    return data_generator(annotation_lines, batch_size, input_shape, anchors, num_classes)\n\nif __name__ == '__main__':\n    _main()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!mv keras-yolo3/model_data/annotations/*.txt keras-yolo3/","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!ls keras-yolo3/*.txt","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#!echo \"10,14,  23,27,  37,58,  81,82,  135,169,  344,319\" > keras-yolo3/model_data/yolo_anchors.txt && ls -l keras-yolo3/model_data/","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!echo \"face\" > keras-yolo3/model_data/voc_classes.txt","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#!wget -O keras-yolo3/model_data/tiny_yolo.weights https://pjreddie.com/media/files/yolov3-tiny.weights\n!wget -O keras-yolo3/model_data/yolov3.weights https://pjreddie.com/media/files/yolov3.weights","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#!wget -O keras-yolo3/model_data/yolov3-tiny.cfg https://raw.githubusercontent.com/pjreddie/darknet/master/cfg/yolov3-tiny.cfg\n!wget -O keras-yolo3/model_data/yolov3.cfg https://raw.githubusercontent.com/pjreddie/darknet/master/cfg/yolov3.cfg","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#!python keras-yolo3/convert.py keras-yolo3/model_data/yolov3-tiny.cfg keras-yolo3/model_data/tiny_yolo.weights keras-yolo3/model_data/tiny_yolo_weights.h5\n!python keras-yolo3/convert.py keras-yolo3/model_data/yolov3.cfg keras-yolo3/model_data/yolov3.weights keras-yolo3/model_data/yolo_weights.h5","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import sys\nimport os\n\nsys.path.insert(0, './keras-yolo3/')\nos.chdir('./keras-yolo3/')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from train import _main\n\n#_main()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* [Model](./keras-yolo3/logs/000/trained_weights_final.h5)\n* [cfg](./keras-yolo3/model_data/yolov3.cfg)\n* [classes](./keras-yolo3/model_data/voc_classes.txt)\n* [anchors](./keras-yolo3/model_data/yolo_anchors.txt)"},{"metadata":{"trusted":true},"cell_type":"code","source":"#!wget -O yolov3.py https://raw.githubusercontent.com/onnx/keras-onnx/master/applications/yolov3/yolov3.py","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%writefile yolov3.py\n# %load yolov3.py\nimport os\nimport sys\nimport inspect\nimport colorsys\nimport onnx\nimport numpy as np\nimport tensorflow as tf\nimport keras\nfrom PIL import Image, ImageFont, ImageDraw\nfrom keras import backend as K\nfrom keras.layers import Input\nfrom keras.models import load_model\nfrom keras2onnx import convert_keras\nfrom keras2onnx import set_converter\nfrom keras2onnx.common.onnx_ops import apply_transpose, apply_identity, apply_cast\nfrom keras2onnx.proto import onnx_proto\n\nimport yolo3\nfrom yolo3.model import yolo_body, tiny_yolo_body, yolo_boxes_and_scores\nfrom yolo3.utils import letterbox_image\n\n\nclass YOLOEvaluationLayer(keras.layers.Layer):\n\n    def __init__(self, **kwargs):\n        super(YOLOEvaluationLayer, self).__init__()\n        self.anchors = np.array(kwargs.get('anchors'))\n        self.num_classes = kwargs.get('num_classes')\n\n    def get_config(self):\n        config = {\n            \"anchors\": self.anchors,\n            \"num_classes\": self.num_classes,\n        }\n\n        return config\n\n    def call(self, inputs, **kwargs):\n        \"\"\"Evaluate YOLO model on given input and return filtered boxes.\"\"\"\n        yolo_outputs = inputs[0:3]\n        input_image_shape = K.squeeze(inputs[3], axis=0)\n        num_layers = len(yolo_outputs)\n        anchor_mask = [[6, 7, 8], [3, 4, 5], [0, 1, 2]] if num_layers == 3 else [[3, 4, 5],\n                                                                                 [1, 2, 3]]  # default setting\n        input_shape = K.shape(yolo_outputs[0])[1:3] * 32\n        boxes = []\n        box_scores = []\n        for l in range(num_layers):\n            _boxes, _box_scores = yolo_boxes_and_scores(yolo_outputs[l], self.anchors[anchor_mask[l]], self.num_classes,\n                                                        input_shape, input_image_shape)\n            boxes.append(_boxes)\n            box_scores.append(_box_scores)\n        boxes = K.concatenate(boxes, axis=0)\n        box_scores = K.concatenate(box_scores, axis=0)\n        return [boxes, box_scores]\n\n    def compute_output_shape(self, input_shape):\n        assert isinstance(input_shape, list)\n        return [(None, 4), (None, None)]\n\n\nclass YOLONMSLayer(keras.layers.Layer):\n    def __init__(self, **kwargs):\n        super(YOLONMSLayer, self).__init__()\n        self.max_boxes = kwargs.get('max_boxes', 20)\n        self.score_threshold = kwargs.get('score_threshold', .6)\n        self.iou_threshold = kwargs.get('iou_threshold', .5)\n        self.num_classes = kwargs.get('num_classes')\n\n    def get_config(self):\n        config = {\n            \"max_boxes\": self.max_boxes,\n            \"score_threshold\": self.score_threshold,\n            \"iou_threshold\": self.iou_threshold,\n            \"num_classes\": self.num_classes,\n        }\n\n        return config\n\n    def call(self, inputs, **kwargs):\n        boxes = inputs[0]\n        box_scores = inputs[1]\n\n        mask = box_scores >= self.score_threshold\n        max_boxes_tensor = K.constant(self.max_boxes, dtype='int32')\n        boxes_ = []\n        scores_ = []\n        classes_ = []\n        for c in range(self.num_classes):\n            class_boxes = tf.boolean_mask(boxes, mask[:, c])\n            class_box_scores = tf.boolean_mask(box_scores[:, c], mask[:, c])\n            nms_index = tf.image.non_max_suppression(\n                class_boxes, class_box_scores, max_boxes_tensor, iou_threshold=self.iou_threshold)\n            class_boxes = K.gather(class_boxes, nms_index)\n            class_box_scores = K.gather(class_box_scores, nms_index)\n            classes = K.ones_like(class_box_scores, 'int32') * c\n            boxes_.append(class_boxes)\n            scores_.append(class_box_scores)\n            classes_.append(classes)\n        boxes_ = K.concatenate(boxes_, axis=0)\n        scores_ = K.concatenate(scores_, axis=0)\n        classes_ = K.concatenate(classes_, axis=0)\n\n        boxes_r = tf.expand_dims(tf.expand_dims(boxes_, 0), 0)\n        scores_r = tf.expand_dims(tf.expand_dims(scores_, 0), 0)\n        return [boxes_r, scores_r, classes_]\n\n    def compute_output_shape(self, input_shape):\n        assert isinstance(input_shape, list)\n        return [(None, None, 4), (None, None, None), (None, None)]\n\n\nclass YOLO(object):\n    def __init__(self):\n        self.model_path = 'model_data/trained_weights_final.h5'  # model path or trained weights path\n        self.anchors_path = 'model_data/yolo_anchors.txt'\n        self.classes_path = 'model_data/coco_classes.txt'\n        self.score = 0.3\n        self.iou = 0.45\n        self.class_names = self._get_class()\n        self.anchors = self._get_anchors()\n        self.sess = K.get_session()\n        self.model_image_size = (416, 416)  # fixed size or (None, None), hw\n        self.session = None\n        self.final_model = None\n\n        # Generate colors for drawing bounding boxes.\n        hsv_tuples = [(x / len(self.class_names), 1., 1.)\n                      for x in range(len(self.class_names))]\n        self.colors = list(map(lambda x: colorsys.hsv_to_rgb(*x), hsv_tuples))\n        self.colors = list(\n            map(lambda x: (int(x[0] * 255), int(x[1] * 255), int(x[2] * 255)),\n                self.colors))\n        np.random.seed(10101)  # Fixed seed for consistent colors across runs.\n        np.random.shuffle(self.colors)  # Shuffle colors to decorrelate adjacent classes.\n        np.random.seed(None)  # Reset seed to default.\n        K.set_learning_phase(0)\n\n    @staticmethod\n    def _get_data_path(name):\n        path = os.path.expanduser(name)\n        if not os.path.isabs(path):\n            yolo3_dir = os.path.dirname(inspect.getabsfile(yolo3))\n            path = os.path.join(yolo3_dir, os.path.pardir, path)\n        return path\n\n    def _get_class(self):\n        classes_path = self._get_data_path(self.classes_path)\n        with open(classes_path) as f:\n            class_names = f.readlines()\n        class_names = [c.strip() for c in class_names]\n        return class_names\n\n    def _get_anchors(self):\n        anchors_path = self._get_data_path(self.anchors_path)\n        with open(anchors_path) as f:\n            anchors = f.readline()\n        anchors = [float(x) for x in anchors.split(',')]\n        return np.array(anchors).reshape(-1, 2)\n\n    def load_model(self):\n        model_path = self._get_data_path(self.model_path)\n        assert model_path.endswith('.h5'), 'Keras model or weights must be a .h5 file.'\n\n        # Load model, or construct model and load weights.\n        num_anchors = len(self.anchors)\n        num_classes = len(self.class_names)\n        is_tiny_version = num_anchors == 6  # default setting\n        try:\n            self.yolo_model = load_model(model_path, compile=False)\n        except:\n            self.yolo_model = tiny_yolo_body(Input(shape=(None, None, 3)), num_anchors // 2, num_classes) \\\n                if is_tiny_version else yolo_body(Input(shape=(None, None, 3)), num_anchors // 3, num_classes)\n            self.yolo_model.load_weights(self.model_path)  # make sure model, anchors and classes match\n        else:\n            assert self.yolo_model.layers[-1].output_shape[-1] == \\\n                num_anchors / len(self.yolo_model.output) * (num_classes + 5), \\\n                'Mismatch between model and given anchor and class sizes'\n\n        input_image_shape = keras.Input(shape=(2,), name='image_shape')\n        image_input = keras.Input((None, None, 3), dtype='float32')\n        y1, y2, y3 = self.yolo_model(image_input)\n\n        boxes, box_scores = \\\n            YOLOEvaluationLayer(anchors=self.anchors, num_classes=len(self.class_names))(\n                inputs=[y1, y2, y3, input_image_shape])\n\n        out_boxes, out_scores, out_indices = \\\n            YOLONMSLayer(anchors=self.anchors, num_classes=len(self.class_names))(\n                inputs=[boxes, box_scores])\n        self.final_model = keras.Model(inputs=[image_input, input_image_shape],\n                                       outputs=[out_boxes, out_scores, out_indices])\n\n        self.final_model.save('model_data/final_model.h5')\n        print('{} model, anchors, and classes loaded.'.format(model_path))\n\n    def detect_with_onnx(self, image):\n        if self.model_image_size != (None, None):\n            assert self.model_image_size[0] % 32 == 0, 'Multiples of 32 required'\n            assert self.model_image_size[1] % 32 == 0, 'Multiples of 32 required'\n            boxed_image = letterbox_image(image, tuple(reversed(self.model_image_size)))\n        else:\n            new_image_size = (image.width - (image.width % 32),\n                              image.height - (image.height % 32))\n            boxed_image = letterbox_image(image, new_image_size)\n        image_data = np.array(boxed_image, dtype='float32')\n        image_data /= 255.\n        image_data = np.transpose(image_data, [2, 0, 1])\n\n        image_data = np.expand_dims(image_data, 0)  # Add batch dimension.\n        feed_f = dict(zip(['input_1', 'image_shape'],\n                          (image_data, np.array([image.size[1], image.size[0]], dtype='float32').reshape(1, 2))))\n        all_boxes, all_scores, indices = self.session.run(None, input_feed=feed_f)\n\n        out_boxes, out_scores, out_classes = [], [], []\n        for idx_ in indices:\n            out_classes.append(idx_[1])\n            out_scores.append(all_scores[tuple(idx_)])\n            idx_1 = (idx_[0], idx_[2])\n            out_boxes.append(all_boxes[idx_1])\n\n        font = ImageFont.truetype(font=self._get_data_path('font/FiraMono-Medium.otf'),\n                                  size=np.floor(3e-2 * image.size[1] + 0.5).astype('int32'))\n        thickness = (image.size[0] + image.size[1]) // 300\n\n        for i, c in reversed(list(enumerate(out_classes))):\n            predicted_class = self.class_names[c]\n            box = out_boxes[i]\n            score = out_scores[i]\n\n            label = '{} {:.2f}'.format(predicted_class, score)\n            draw = ImageDraw.Draw(image)\n            label_size = draw.textsize(label, font)\n\n            top, left, bottom, right = box\n            top = max(0, np.floor(top + 0.5).astype('int32'))\n            left = max(0, np.floor(left + 0.5).astype('int32'))\n            bottom = min(image.size[1], np.floor(bottom + 0.5).astype('int32'))\n            right = min(image.size[0], np.floor(right + 0.5).astype('int32'))\n\n            if top - label_size[1] >= 0:\n                text_origin = np.array([left, top - label_size[1]])\n            else:\n                text_origin = np.array([left, top + 1])\n\n            for i in range(thickness):\n                draw.rectangle(\n                    [left + i, top + i, right - i, bottom - i],\n                    outline=self.colors[c])\n            draw.rectangle(\n                [tuple(text_origin), tuple(text_origin + label_size)],\n                fill=self.colors[c])\n            draw.text(text_origin, label, fill=(0, 0, 0), font=font)\n            del draw\n\n        return image\n\n\ndef detect_img(yolo, img_url, model_file_name):\n    import onnxruntime\n    image = Image.open(img_url)\n    yolo.session = onnxruntime.InferenceSession(model_file_name)\n\n    r_image = yolo.detect_with_onnx(image)\n    n_ext = img_url.rindex('.')\n    score_file = img_url[0:n_ext] + '_score' + img_url[n_ext:]\n    r_image.save(score_file, \"JPEG\")\n\n\ndef convert_NMSLayer(scope, operator, container):\n    # type: (keras2onnx.common.InterimContext, keras2onnx.common.Operator, keras2onnx.common.OnnxObjectContainer) -> None\n    box_transpose = scope.get_unique_variable_name(operator.inputs[0].full_name + '_tx')\n    score_transpose = scope.get_unique_variable_name(operator.inputs[1].full_name + '_tx')\n\n    apply_identity(scope, operator.inputs[0].full_name, box_transpose, container)\n    apply_transpose(scope, operator.inputs[1].full_name, score_transpose, container, perm=[1, 0])\n\n    box_batch = scope.get_unique_variable_name(operator.inputs[0].full_name + '_btc')\n    score_batch = scope.get_unique_variable_name(operator.inputs[1].full_name + '_btc')\n\n    container.add_node(\"Unsqueeze\", box_transpose,\n                       box_batch, op_version=operator.target_opset, axes=[0])\n    container.add_node(\"Unsqueeze\", score_transpose,\n                       score_batch, op_version=operator.target_opset, axes=[0])\n\n    layer = operator.raw_operator  # type: YOLONMSLayer\n\n    max_output_size = scope.get_unique_variable_name('max_output_size')\n    iou_threshold = scope.get_unique_variable_name('iou_threshold')\n    score_threshold = scope.get_unique_variable_name('layer.score_threshold')\n\n    container.add_initializer(max_output_size, onnx_proto.TensorProto.INT64,\n                              [], [layer.max_boxes])\n    container.add_initializer(iou_threshold, onnx_proto.TensorProto.FLOAT,\n                              [], [layer.iou_threshold])\n    container.add_initializer(score_threshold, onnx_proto.TensorProto.FLOAT,\n                              [], [layer.score_threshold])\n\n    cast_name = scope.get_unique_variable_name('casted')\n    nms_node = next((nd_ for nd_ in operator.nodelist if nd_.type == 'NonMaxSuppressionV3'), operator.nodelist[0])\n    container.add_node(\"NonMaxSuppression\",\n                       [box_batch, score_batch, max_output_size, iou_threshold, score_threshold],\n                       cast_name,\n                       op_version=operator.target_opset,\n                       name=nms_node.name)\n    apply_cast(scope, cast_name, operator.output_full_names[2], container, to=onnx_proto.TensorProto.INT32)\n\n    apply_identity(scope, box_batch, operator.output_full_names[0], container)\n    apply_identity(scope, score_batch, operator.output_full_names[1], container)\n\n\nset_converter(YOLONMSLayer, convert_NMSLayer)\n\n\ndef convert_model(yolo, model_file_name, target_opset):\n    yolo.load_model()\n    onnxmodel = convert_keras(yolo.final_model, target_opset=target_opset, channel_first_inputs=['input_1'])\n    onnx.save_model(onnxmodel, model_file_name)\n    return onnxmodel\n\n\nif __name__ == '__main__':\n    if len(sys.argv) < 2:\n        print(\"Need an image file for object detection.\")\n        exit(-1)\n\n    model_file_name = 'model_data/yolov3.onnx'\n    target_opset = 10\n\n    if not os.path.exists(model_file_name):\n        onnxmodel = convert_model(YOLO(), model_file_name, target_opset)\n\n    detect_img(YOLO(), sys.argv[1], model_file_name)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#!python yolov3.py 'http://www.ncsl.org/portals/1/ImageLibrary_New/Miscellaneous/businesswoman-leading-meeting-504987926_1x.jpg'","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}